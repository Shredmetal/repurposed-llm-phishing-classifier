{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T14:18:26.169089Z",
     "start_time": "2025-01-28T14:18:25.186887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n"
   ],
   "id": "6c66ffe4655abc5e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "GPU Device: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T14:18:28.351014Z",
     "start_time": "2025-01-28T14:18:28.344825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "huggingface_api_key = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "wandb_api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "\n",
    "if not huggingface_api_key:\n",
    "    raise ValueError(\"HUGGINGFACE_API_KEY not set\")\n",
    "\n",
    "if not wandb_api_key:\n",
    "    raise ValueError(\"WANDB_API_KEY not set\")"
   ],
   "id": "e533277720089dcf",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T14:18:32.953836Z",
     "start_time": "2025-01-28T14:18:29.968539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging\n",
    ")\n",
    "\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model\n",
    ")\n",
    "\n",
    "import wandb\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from trl import SFTTrainer, setup_chat_format"
   ],
   "id": "9e21f997b648e218",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\PyCharm\\PycharmProjects\\repurposed-llm-phishing-classifier\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T14:18:40.830809Z",
     "start_time": "2025-01-28T14:18:40.546692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=huggingface_api_key)"
   ],
   "id": "aaafa79785bc72a5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T14:18:44.253579Z",
     "start_time": "2025-01-28T14:18:42.129920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wandb.login(key=wandb_api_key)\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"repurposed-llm-phishing-classifier\",\n",
    "    job_type=\"train\",\n",
    "    anonymous=\"allow\"\n",
    ")"
   ],
   "id": "1e197bf918aa209e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: morganj-lee01 (morganj-lee01-synpulse8). Use `wandb login --relogin` to force relogin\n",
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\morga\\_netrc\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>E:\\PyCharm\\PycharmProjects\\repurposed-llm-phishing-classifier\\notebooks\\wandb\\run-20250128_221843-849jvo1i</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/morganj-lee01-synpulse8/repurposed-llm-phishing-classifier/runs/849jvo1i?apiKey=2a1b3aadd29eb165c80f5d6458a4058c07a5a986' target=\"_blank\">noble-waterfall-1</a></strong> to <a href='https://wandb.ai/morganj-lee01-synpulse8/repurposed-llm-phishing-classifier?apiKey=2a1b3aadd29eb165c80f5d6458a4058c07a5a986' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/morganj-lee01-synpulse8/repurposed-llm-phishing-classifier?apiKey=2a1b3aadd29eb165c80f5d6458a4058c07a5a986' target=\"_blank\">https://wandb.ai/morganj-lee01-synpulse8/repurposed-llm-phishing-classifier?apiKey=2a1b3aadd29eb165c80f5d6458a4058c07a5a986</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/morganj-lee01-synpulse8/repurposed-llm-phishing-classifier/runs/849jvo1i?apiKey=2a1b3aadd29eb165c80f5d6458a4058c07a5a986' target=\"_blank\">https://wandb.ai/morganj-lee01-synpulse8/repurposed-llm-phishing-classifier/runs/849jvo1i?apiKey=2a1b3aadd29eb165c80f5d6458a4058c07a5a986</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Do NOT share these links with anyone. They can be used to claim your runs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T14:18:51.668068Z",
     "start_time": "2025-01-28T14:18:51.665520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_model_path = \"../models/llama_models/llama-3.2-3B\"\n",
    "new_model_path = \"../models/tuned_models/llama-3.2-3B-phishing-classifier\"\n",
    "dataset_path = \"../processed_data/train.csv\""
   ],
   "id": "510dfcf5597f3943",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T14:18:54.011538Z",
     "start_time": "2025-01-28T14:18:53.721877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = pd.read_csv(dataset_path)\n",
    "\n",
    "train_df.head()"
   ],
   "id": "a9e9e085312d0019",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                              system  \\\n",
       "0  You are a classification system designed to ca...   \n",
       "1  You are a classification system designed to ca...   \n",
       "2  You are a classification system designed to ca...   \n",
       "3  You are a classification system designed to ca...   \n",
       "4  You are a classification system designed to ca...   \n",
       "\n",
       "                                                user  assistant  \n",
       "0  Message for review: write me back please year ...       True  \n",
       "1  Message for review: I just picked up Razor SDK...      False  \n",
       "2  Message for review: vacation goodmorning , i w...      False  \n",
       "3  Message for review: On Thu, Aug 08, 2002 at 11...      False  \n",
       "4  Message for review: wellheads shoreline has se...      False  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system</th>\n",
       "      <th>user</th>\n",
       "      <th>assistant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are a classification system designed to ca...</td>\n",
       "      <td>Message for review: write me back please year ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are a classification system designed to ca...</td>\n",
       "      <td>Message for review: I just picked up Razor SDK...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are a classification system designed to ca...</td>\n",
       "      <td>Message for review: vacation goodmorning , i w...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You are a classification system designed to ca...</td>\n",
       "      <td>Message for review: On Thu, Aug 08, 2002 at 11...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are a classification system designed to ca...</td>\n",
       "      <td>Message for review: wellheads shoreline has se...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T14:18:59.623308Z",
     "start_time": "2025-01-28T14:18:59.619918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_config = {\n",
    "    \"torch_dtype\": torch.bfloat16,\n",
    "    \"attn_implementation\": \"flash_attention_2\",\n",
    "    \"device_map\": \"auto\"\n",
    "}"
   ],
   "id": "51d47220f5319bbf",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T14:19:01.893235Z",
     "start_time": "2025-01-28T14:19:01.361030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# WARNING: flash_attention_2 required pip install flash-attn which needs C++ builds tools\n",
    "# It also takes absolutely forever to compile because it's compiling CUDA kernels\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_path,\n",
    "    device_map=model_config[\"device_map\"],\n",
    "    torch_dtype=model_config[\"torch_dtype\"],\n",
    "    attn_implementation=model_config[\"attn_implementation\"]\n",
    ")"
   ],
   "id": "ce3db8ac1a8d05c8",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "FlashAttention2 has been toggled on, but it cannot be used due to the following error: the package flash_attn seems to be not installed. Please refer to the documentation of https://huggingface.co/docs/transformers/perf_infer_gpu_one#flashattention-2 to install Flash Attention 2.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mAutoModelForCausalLM\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbase_model_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_config\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdevice_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtorch_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_config\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtorch_dtype\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattn_implementation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_config\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mattn_implementation\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\PyCharm\\PycharmProjects\\repurposed-llm-phishing-classifier\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:564\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m    562\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(config) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m    563\u001B[0m     model_class \u001B[38;5;241m=\u001B[39m _get_model_class(config, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping)\n\u001B[1;32m--> 564\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_class\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    565\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    566\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    567\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    568\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    569\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(c\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    570\u001B[0m )\n",
      "File \u001B[1;32mE:\\PyCharm\\PycharmProjects\\repurposed-llm-phishing-classifier\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:4084\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m   4082\u001B[0m config \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mdeepcopy(config)  \u001B[38;5;66;03m# We do not want to modify the config inplace in from_pretrained.\u001B[39;00m\n\u001B[0;32m   4083\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(config, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_attn_implementation_autoset\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m-> 4084\u001B[0m     config \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_autoset_attn_implementation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   4085\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_flash_attention_2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_flash_attention_2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice_map\u001B[49m\n\u001B[0;32m   4086\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4088\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ContextManagers(init_contexts):\n\u001B[0;32m   4089\u001B[0m     \u001B[38;5;66;03m# Let's make sure we don't run the init function of buffer modules\u001B[39;00m\n\u001B[0;32m   4090\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m(config, \u001B[38;5;241m*\u001B[39mmodel_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs)\n",
      "File \u001B[1;32mE:\\PyCharm\\PycharmProjects\\repurposed-llm-phishing-classifier\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:1525\u001B[0m, in \u001B[0;36mPreTrainedModel._autoset_attn_implementation\u001B[1;34m(cls, config, use_flash_attention_2, torch_dtype, device_map, check_device_map)\u001B[0m\n\u001B[0;32m   1522\u001B[0m     config\u001B[38;5;241m.\u001B[39m_attn_implementation \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mflash_attention_2\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m config\u001B[38;5;241m.\u001B[39m_attn_implementation \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mflash_attention_2\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m-> 1525\u001B[0m     \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_and_enable_flash_attn_2\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1526\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1527\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtorch_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1528\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1529\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhard_check_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1530\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_device_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_device_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1531\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1532\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m requested_attn_implementation \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mflex_attention\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1533\u001B[0m     config \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_check_and_enable_flex_attn(config, hard_check_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32mE:\\PyCharm\\PycharmProjects\\repurposed-llm-phishing-classifier\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:1659\u001B[0m, in \u001B[0;36mPreTrainedModel._check_and_enable_flash_attn_2\u001B[1;34m(cls, config, torch_dtype, device_map, check_device_map, hard_check_only)\u001B[0m\n\u001B[0;32m   1656\u001B[0m install_message \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease refer to the documentation of https://huggingface.co/docs/transformers/perf_infer_gpu_one#flashattention-2 to install Flash Attention 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1658\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m importlib\u001B[38;5;241m.\u001B[39mutil\u001B[38;5;241m.\u001B[39mfind_spec(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mflash_attn\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1659\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpreface\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m the package flash_attn seems to be not installed. \u001B[39m\u001B[38;5;132;01m{\u001B[39;00minstall_message\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1661\u001B[0m flash_attention_version \u001B[38;5;241m=\u001B[39m version\u001B[38;5;241m.\u001B[39mparse(importlib\u001B[38;5;241m.\u001B[39mmetadata\u001B[38;5;241m.\u001B[39mversion(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mflash_attn\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m   1662\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mversion\u001B[38;5;241m.\u001B[39mcuda:\n",
      "\u001B[1;31mImportError\u001B[0m: FlashAttention2 has been toggled on, but it cannot be used due to the following error: the package flash_attn seems to be not installed. Please refer to the documentation of https://huggingface.co/docs/transformers/perf_infer_gpu_one#flashattention-2 to install Flash Attention 2."
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tokenizer = AutoTokenizer.from_pretrained(base_model_path, trust_remote_code=True)",
   "id": "8020da79ce3618a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"your_phishing_data.csv\")\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "def format_chat_template(row):\n",
    "\n",
    "    row_json = [\n",
    "        {\"role\": \"system\", \"content\": row[\"system\"]},\n",
    "        {\"role\": \"user\", \"content\": row[\"user\"]},\n",
    "        {\"role\": \"assistant\", \"content\": row[\"assistant\"]}\n",
    "    ]\n",
    "\n",
    "    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n",
    "    return row\n",
    "\n",
    "formatted_dataset = dataset.map(\n",
    "    format_chat_template,\n",
    "    num_proc=4,\n",
    ")"
   ],
   "id": "bf843b706515345b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
